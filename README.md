# Hand Gesture Recognition with OpenCV, Pytorch, and YOLOv5

<img src="./sign_lang_detection/sl_run.gif" width='600'/>

##   
<img src="./basic_thresholding/finger_count.gif" width="300" height='250'/> <img src="./pytorch_classification/classification.gif" width="300" height='250'/>

## Overview


This project is a culmination of three separate methods in computer vision to detect hand gestures.  The first uses basic image thresholding with openCV to find contours of fingers after applying a mask.  The second uses machine learning principles in pytorch to create a CNN for image classification.  The third uses object detection with YOLOv5 to recognize all the letters of the alphabet in American Sign Language (J and Z edited).  You can learn more about each project, as well as how to run them, in their individual README's. Below are instructions on setting up a virtual environment that will be able to run all three projects. There's also a brief report on what I learned about machine learning and my thoughts on improvements.   

## Setting Up a Virtual Environment
- Create a new environment with python 3.8.  If you'd like, you can do this with venv "python3.8 -m venv /path/venv" and enter the environment. "source /path/venv/bin/activate"
- Download the correct version of pytorch 1.6. https://pytorch.org/
- Install dependencies " pip3 install -r requirements.txt"

## Machine Learning Basics

## Creating a Custom Data Set Automatically

## Improvements

## Special Thanks
